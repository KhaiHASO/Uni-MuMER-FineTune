{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"gpu","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Uni-MuMER Project - Kaggle Setup\n\nNotebook này cài đặt và chạy Uni-MuMER Project trên Kaggle với Python 3.10 và conda","metadata":{}},{"cell_type":"code","source":"# Cài đặt Miniconda vào thư mục có quyền ghi\n!wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n!bash Miniconda3-latest-Linux-x86_64.sh -b -f -p /kaggle/working/miniconda\n!rm Miniconda3-latest-Linux-x86_64.sh\n\n# Đồng ý điều khoản của Anaconda (Bắt buộc để cài đặt các package từ channel main/r)\n!/kaggle/working/miniconda/bin/conda tos accept --override-channels --channel https://repo.anaconda.com/pkgs/main\n!/kaggle/working/miniconda/bin/conda tos accept --override-channels --channel https://repo.anaconda.com/pkgs/r\n\n# Tạo môi trường unimumer với Python 3.10\n!/kaggle/working/miniconda/bin/conda create -n unimumer python=3.10 -y","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T05:41:35.187115Z","iopub.execute_input":"2025-12-27T05:41:35.187402Z","iopub.status.idle":"2025-12-27T05:42:03.155312Z","shell.execute_reply.started":"2025-12-27T05:41:35.187381Z","shell.execute_reply":"2025-12-27T05:42:03.154321Z"}},"outputs":[{"name":"stdout","text":"--2025-12-27 05:41:35--  https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\nResolving repo.anaconda.com (repo.anaconda.com)... 104.16.191.158, 104.16.32.241, 2606:4700::6810:20f1, ...\nConnecting to repo.anaconda.com (repo.anaconda.com)|104.16.191.158|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 156772981 (150M) [application/octet-stream]\nSaving to: ‘Miniconda3-latest-Linux-x86_64.sh’\n\nMiniconda3-latest-L 100%[===================>] 149.51M   185MB/s    in 0.8s    \n\n2025-12-27 05:41:36 (185 MB/s) - ‘Miniconda3-latest-Linux-x86_64.sh’ saved [156772981/156772981]\n\nPREFIX=/kaggle/working/miniconda\nUnpacking bootstrapper...\nUnpacking payload...\n\nInstalling base environment...\n\nPreparing transaction: ...working... done\nExecuting transaction: ...working... done\ninstallation finished.\nWARNING:\n    You currently have a PYTHONPATH environment variable set. This may cause\n    unexpected behavior when running the Python interpreter in Miniconda3.\n    For best results, please verify that your PYTHONPATH only points to\n    directories of packages that are compatible with the Python interpreter\n    in Miniconda3: /kaggle/working/miniconda\naccepted Terms of Service for \u001b[4;94mhttps://repo.anaconda.com/pkgs/main\u001b[0m\naccepted Terms of Service for \u001b[4;94mhttps://repo.anaconda.com/pkgs/r\u001b[0m\n\u001b[1;32m2\u001b[0m\u001b[1;32m channel Terms of Service accepted\u001b[0m\nRetrieving notices: done\nChannels:\n - defaults\nPlatform: linux-64\nCollecting package metadata (repodata.json): done\nSolving environment: done\n\n## Package Plan ##\n\n  environment location: /kaggle/working/miniconda/envs/unimumer\n\n  added / updated specs:\n    - python=3.10\n\n\nThe following packages will be downloaded:\n\n    package                    |            build\n    ---------------------------|-----------------\n    libnsl-2.0.0               |       h5eee18b_0          31 KB\n    python-3.10.19             |       h6fa692b_0        24.5 MB\n    setuptools-80.9.0          |  py310h06a4308_0         1.4 MB\n    wheel-0.45.1               |  py310h06a4308_0         115 KB\n    ------------------------------------------------------------\n                                           Total:        26.0 MB\n\nThe following NEW packages will be INSTALLED:\n\n  _libgcc_mutex      pkgs/main/linux-64::_libgcc_mutex-0.1-main \n  _openmp_mutex      pkgs/main/linux-64::_openmp_mutex-5.1-1_gnu \n  bzip2              pkgs/main/linux-64::bzip2-1.0.8-h5eee18b_6 \n  ca-certificates    pkgs/main/linux-64::ca-certificates-2025.12.2-h06a4308_0 \n  expat              pkgs/main/linux-64::expat-2.7.3-h7354ed3_4 \n  ld_impl_linux-64   pkgs/main/linux-64::ld_impl_linux-64-2.44-h153f514_2 \n  libexpat           pkgs/main/linux-64::libexpat-2.7.3-h7354ed3_4 \n  libffi             pkgs/main/linux-64::libffi-3.4.4-h6a678d5_1 \n  libgcc             pkgs/main/linux-64::libgcc-15.2.0-h69a1729_7 \n  libgcc-ng          pkgs/main/linux-64::libgcc-ng-15.2.0-h166f726_7 \n  libgomp            pkgs/main/linux-64::libgomp-15.2.0-h4751f2c_7 \n  libnsl             pkgs/main/linux-64::libnsl-2.0.0-h5eee18b_0 \n  libstdcxx          pkgs/main/linux-64::libstdcxx-15.2.0-h39759b7_7 \n  libstdcxx-ng       pkgs/main/linux-64::libstdcxx-ng-15.2.0-hc03a8fd_7 \n  libuuid            pkgs/main/linux-64::libuuid-1.41.5-h5eee18b_0 \n  libxcb             pkgs/main/linux-64::libxcb-1.17.0-h9b100fa_0 \n  libzlib            pkgs/main/linux-64::libzlib-1.3.1-hb25bd0a_0 \n  ncurses            pkgs/main/linux-64::ncurses-6.5-h7934f7d_0 \n  openssl            pkgs/main/linux-64::openssl-3.0.18-hd6dcaed_0 \n  pip                pkgs/main/noarch::pip-25.3-pyhc872135_0 \n  pthread-stubs      pkgs/main/linux-64::pthread-stubs-0.3-h0ce48e5_1 \n  python             pkgs/main/linux-64::python-3.10.19-h6fa692b_0 \n  readline           pkgs/main/linux-64::readline-8.3-hc2a1206_0 \n  setuptools         pkgs/main/linux-64::setuptools-80.9.0-py310h06a4308_0 \n  sqlite             pkgs/main/linux-64::sqlite-3.51.0-h2a70700_0 \n  tk                 pkgs/main/linux-64::tk-8.6.15-h54e0aa7_0 \n  tzdata             pkgs/main/noarch::tzdata-2025b-h04d1e81_0 \n  wheel              pkgs/main/linux-64::wheel-0.45.1-py310h06a4308_0 \n  xorg-libx11        pkgs/main/linux-64::xorg-libx11-1.8.12-h9b100fa_1 \n  xorg-libxau        pkgs/main/linux-64::xorg-libxau-1.0.12-h9b100fa_0 \n  xorg-libxdmcp      pkgs/main/linux-64::xorg-libxdmcp-1.1.5-h9b100fa_0 \n  xorg-xorgproto     pkgs/main/linux-64::xorg-xorgproto-2024.1-h5eee18b_1 \n  xz                 pkgs/main/linux-64::xz-5.6.4-h5eee18b_1 \n  zlib               pkgs/main/linux-64::zlib-1.3.1-hb25bd0a_0 \n\n\n\nDownloading and Extracting Packages:\npython-3.10.19       | 24.5 MB   |                                       |   0% \nsetuptools-80.9.0    | 1.4 MB    |                                       |   0% \u001b[A\n\nwheel-0.45.1         | 115 KB    |                                       |   0% \u001b[A\u001b[A\n\n\npython-3.10.19       | 24.5 MB   |                                       |   0% \u001b[A\u001b[A\u001b[A\n\nwheel-0.45.1         | 115 KB    | #####1                                |  14% \u001b[A\u001b[A\n\n\nlibnsl-2.0.0         | 31 KB     | ###################                   |  52% \u001b[A\u001b[A\u001b[A\n\n\nlibnsl-2.0.0         | 31 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\n\nwheel-0.45.1         | 115 KB    | ##################################### | 100% \u001b[A\u001b[A\n\n\nlibnsl-2.0.0         | 31 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\n\npython-3.10.19       | 24.5 MB   | ##########9                           |  30% \u001b[A\u001b[A\nsetuptools-80.9.0    | 1.4 MB    | 4                                     |   1% \u001b[A\nsetuptools-80.9.0    | 1.4 MB    | ###################3                  |  52% \u001b[A\npython-3.10.19       | 24.5 MB   | ##################################### | 100% \u001b[A\nsetuptools-80.9.0    | 1.4 MB    | ##################################### | 100% \u001b[A\n                                                                                \u001b[A\n                                                                                \u001b[A\n\n                                                                                \u001b[A\u001b[A\n\n\n                                                                                \u001b[A\u001b[A\u001b[A\nPreparing transaction: done\nVerifying transaction: done\nExecuting transaction: done\n#\n# To activate this environment, use\n#\n#     $ conda activate unimumer\n#\n# To deactivate an active environment, use\n#\n#     $ conda deactivate\n\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"\n# --- BƯỚC 2: CLONE & TẢI MODEL ---\nACTIVATE = \"source /kaggle/working/miniconda/bin/activate unimumer\"\n\n!git clone https://github.com/KhaiHASO/Uni-MuMER-FineTune.git\n%cd Uni-MuMER-FineTune\n\n# Đã vào trong Uni-MuMER-FineTune, giờ mới có folder Uni-MuMER-Qwen2.5-VL-3B\nMODEL_DIR = \"Uni-MuMER-Qwen2.5-VL-3B\"\n\n# Tải model (Thêm -L để xử lý redirect từ Hugging Face)\n!{ACTIVATE} && wget -L -O {MODEL_DIR}/model-00001-of-00002.safetensors \"https://huggingface.co/phxember/Uni-MuMER-Qwen2.5-VL-3B/resolve/main/model-00001-of-00002.safetensors?download=true\"\n!{ACTIVATE} && wget -L -O {MODEL_DIR}/model-00002-of-00002.safetensors \"https://huggingface.co/phxember/Uni-MuMER-Qwen2.5-VL-3B/resolve/main/model-00002-of-00002.safetensors?download=true\"\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T06:00:45.481626Z","iopub.execute_input":"2025-12-27T06:00:45.481879Z","iopub.status.idle":"2025-12-27T06:01:29.733401Z","shell.execute_reply.started":"2025-12-27T06:00:45.481856Z","shell.execute_reply":"2025-12-27T06:01:29.732677Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'Uni-MuMER-FineTune'...\nremote: Enumerating objects: 652, done.\u001b[K\nremote: Counting objects: 100% (652/652), done.\u001b[K\nremote: Compressing objects: 100% (425/425), done.\u001b[K\nremote: Total 652 (delta 221), reused 641 (delta 210), pack-reused 0 (from 0)\u001b[K\nReceiving objects: 100% (652/652), 14.40 MiB | 23.11 MiB/s, done.\nResolving deltas: 100% (221/221), done.\n/kaggle/working/Uni-MuMER-FineTune\n--2025-12-27 06:00:48--  https://huggingface.co/phxember/Uni-MuMER-Qwen2.5-VL-3B/resolve/main/model-00001-of-00002.safetensors?download=true\nResolving huggingface.co (huggingface.co)... 13.226.251.20, 13.226.251.66, 13.226.251.81, ...\nConnecting to huggingface.co (huggingface.co)|13.226.251.20|:443... connected.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://cas-bridge.xethub.hf.co/xet-bridge-us/68353d4f2da10c54bbbd6a4c/e3c6bba6468762f3f5828469c76764a6152f96fc6aa9f102ef8b917f2aafc7c7?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=cas%2F20251227%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20251227T060048Z&X-Amz-Expires=3600&X-Amz-Signature=b39ee70acd8a092b67a199736d17baf4890d0dcf857da86d4d715ac8a771dbc9&X-Amz-SignedHeaders=host&X-Xet-Cas-Uid=public&response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27model-00001-of-00002.safetensors%3B+filename%3D%22model-00001-of-00002.safetensors%22%3B&x-id=GetObject&Expires=1766818848&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc2NjgxODg0OH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82ODM1M2Q0ZjJkYTEwYzU0YmJiZDZhNGMvZTNjNmJiYTY0Njg3NjJmM2Y1ODI4NDY5Yzc2NzY0YTYxNTJmOTZmYzZhYTlmMTAyZWY4YjkxN2YyYWFmYzdjNyoifV19&Signature=izDUaFs6QdrdwpXBtbLiPr%7ENv15xUsXJgidrCQMGnf6nvGZWRb6BtGKQzxbIVg538RelQA8Cgf5tcJJ5Uk6EP7AKf3iZrb%7EcjpSiHu5MoWFQnmPK88dYELytyPEiA0ZX4i-5wxGmoYCgKZvQ74GFRXC6ql7wPFh-FLuMYAy6hGITMySfCxn3WI53Z0FDDHAWVenVdbcckyolY2SCtCyCDTAQQHNAApkbeUJWY4ZJHDXwrGbTpXitnGEDbIvSdRixanlFEq1e5mPlL49staPnytm1gQ0wEUFmudqMr0F1tD9MTduhGdBSQauyl2s0wJDeBf10hURrTZc8FUvfF9nBmg__&Key-Pair-Id=K2L8F4GPSG1IFC [following]\n--2025-12-27 06:00:48--  https://cas-bridge.xethub.hf.co/xet-bridge-us/68353d4f2da10c54bbbd6a4c/e3c6bba6468762f3f5828469c76764a6152f96fc6aa9f102ef8b917f2aafc7c7?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=cas%2F20251227%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20251227T060048Z&X-Amz-Expires=3600&X-Amz-Signature=b39ee70acd8a092b67a199736d17baf4890d0dcf857da86d4d715ac8a771dbc9&X-Amz-SignedHeaders=host&X-Xet-Cas-Uid=public&response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27model-00001-of-00002.safetensors%3B+filename%3D%22model-00001-of-00002.safetensors%22%3B&x-id=GetObject&Expires=1766818848&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc2NjgxODg0OH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82ODM1M2Q0ZjJkYTEwYzU0YmJiZDZhNGMvZTNjNmJiYTY0Njg3NjJmM2Y1ODI4NDY5Yzc2NzY0YTYxNTJmOTZmYzZhYTlmMTAyZWY4YjkxN2YyYWFmYzdjNyoifV19&Signature=izDUaFs6QdrdwpXBtbLiPr%7ENv15xUsXJgidrCQMGnf6nvGZWRb6BtGKQzxbIVg538RelQA8Cgf5tcJJ5Uk6EP7AKf3iZrb%7EcjpSiHu5MoWFQnmPK88dYELytyPEiA0ZX4i-5wxGmoYCgKZvQ74GFRXC6ql7wPFh-FLuMYAy6hGITMySfCxn3WI53Z0FDDHAWVenVdbcckyolY2SCtCyCDTAQQHNAApkbeUJWY4ZJHDXwrGbTpXitnGEDbIvSdRixanlFEq1e5mPlL49staPnytm1gQ0wEUFmudqMr0F1tD9MTduhGdBSQauyl2s0wJDeBf10hURrTZc8FUvfF9nBmg__&Key-Pair-Id=K2L8F4GPSG1IFC\nResolving cas-bridge.xethub.hf.co (cas-bridge.xethub.hf.co)... 13.226.251.62, 13.226.251.23, 13.226.251.57, ...\nConnecting to cas-bridge.xethub.hf.co (cas-bridge.xethub.hf.co)|13.226.251.62|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 4997750760 (4.7G)\nSaving to: ‘Uni-MuMER-Qwen2.5-VL-3B/model-00001-of-00002.safetensors’\n\nUni-MuMER-Qwen2.5-V 100%[===================>]   4.65G   163MB/s    in 26s     \n\n2025-12-27 06:01:15 (181 MB/s) - ‘Uni-MuMER-Qwen2.5-VL-3B/model-00001-of-00002.safetensors’ saved [4997750760/4997750760]\n\n--2025-12-27 06:01:16--  https://huggingface.co/phxember/Uni-MuMER-Qwen2.5-VL-3B/resolve/main/model-00002-of-00002.safetensors?download=true\nResolving huggingface.co (huggingface.co)... 13.226.251.66, 13.226.251.20, 13.226.251.112, ...\nConnecting to huggingface.co (huggingface.co)|13.226.251.66|:443... connected.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://cas-bridge.xethub.hf.co/xet-bridge-us/68353d4f2da10c54bbbd6a4c/59bc97d141fc8ddac0f4c7bb7c80740537b215bad4ca3fc3b16b5313ade5bbf3?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=cas%2F20251227%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20251227T060116Z&X-Amz-Expires=3600&X-Amz-Signature=ecd99d2240c5ad7fcfba6ea0b7ae8f7a15c09c76997f201fc229040878ccc8d1&X-Amz-SignedHeaders=host&X-Xet-Cas-Uid=public&response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27model-00002-of-00002.safetensors%3B+filename%3D%22model-00002-of-00002.safetensors%22%3B&x-id=GetObject&Expires=1766818876&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc2NjgxODg3Nn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82ODM1M2Q0ZjJkYTEwYzU0YmJiZDZhNGMvNTliYzk3ZDE0MWZjOGRkYWMwZjRjN2JiN2M4MDc0MDUzN2IyMTViYWQ0Y2EzZmMzYjE2YjUzMTNhZGU1YmJmMyoifV19&Signature=Yd6FnGEcoBKWj%7EBO6Y7QzYBN0-G35f-fFOXzlJoknr44jEyaX%7Ezuw9iHOQgNOraQ5%7EG8SLm0HabzcKFn88Ev904STtwtlbK4iWIEb7qCdtUSiJub-QDqU0AGH9Sf8snxjGqFKnjr36n5jkycIWmjuBOZdDuIpqJQCXt5tAcWJlAIpvlbaX0AxxvedV8S7-IFzhbR-gy77nfCuUPreSADAaGzy2B8k4AlaYFpIkqYfl7i%7E9vOx9Sj3qDzsp1jJWL96v%7EQVW9QaXAWlfbKzC5Wq5LZv6b4MAvLtOmWdkXH2UXzlqKb-ITcAVnv4M8KBSQ-xk-TQgV3oeLv6ZKtVMg%7ETA__&Key-Pair-Id=K2L8F4GPSG1IFC [following]\n--2025-12-27 06:01:16--  https://cas-bridge.xethub.hf.co/xet-bridge-us/68353d4f2da10c54bbbd6a4c/59bc97d141fc8ddac0f4c7bb7c80740537b215bad4ca3fc3b16b5313ade5bbf3?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=cas%2F20251227%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20251227T060116Z&X-Amz-Expires=3600&X-Amz-Signature=ecd99d2240c5ad7fcfba6ea0b7ae8f7a15c09c76997f201fc229040878ccc8d1&X-Amz-SignedHeaders=host&X-Xet-Cas-Uid=public&response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27model-00002-of-00002.safetensors%3B+filename%3D%22model-00002-of-00002.safetensors%22%3B&x-id=GetObject&Expires=1766818876&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc2NjgxODg3Nn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82ODM1M2Q0ZjJkYTEwYzU0YmJiZDZhNGMvNTliYzk3ZDE0MWZjOGRkYWMwZjRjN2JiN2M4MDc0MDUzN2IyMTViYWQ0Y2EzZmMzYjE2YjUzMTNhZGU1YmJmMyoifV19&Signature=Yd6FnGEcoBKWj%7EBO6Y7QzYBN0-G35f-fFOXzlJoknr44jEyaX%7Ezuw9iHOQgNOraQ5%7EG8SLm0HabzcKFn88Ev904STtwtlbK4iWIEb7qCdtUSiJub-QDqU0AGH9Sf8snxjGqFKnjr36n5jkycIWmjuBOZdDuIpqJQCXt5tAcWJlAIpvlbaX0AxxvedV8S7-IFzhbR-gy77nfCuUPreSADAaGzy2B8k4AlaYFpIkqYfl7i%7E9vOx9Sj3qDzsp1jJWL96v%7EQVW9QaXAWlfbKzC5Wq5LZv6b4MAvLtOmWdkXH2UXzlqKb-ITcAVnv4M8KBSQ-xk-TQgV3oeLv6ZKtVMg%7ETA__&Key-Pair-Id=K2L8F4GPSG1IFC\nResolving cas-bridge.xethub.hf.co (cas-bridge.xethub.hf.co)... 13.226.251.62, 13.226.251.23, 13.226.251.118, ...\nConnecting to cas-bridge.xethub.hf.co (cas-bridge.xethub.hf.co)|13.226.251.62|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 3133917248 (2.9G)\nSaving to: ‘Uni-MuMER-Qwen2.5-VL-3B/model-00002-of-00002.safetensors’\n\nUni-MuMER-Qwen2.5-V 100%[===================>]   2.92G   214MB/s    in 13s     \n\n2025-12-27 06:01:29 (225 MB/s) - ‘Uni-MuMER-Qwen2.5-VL-3B/model-00002-of-00002.safetensors’ saved [3133917248/3133917248]\n\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"# --- BƯỚC 3: CÀI ĐẶT THƯ VIỆN ---\n# Lưu ý: CUDA 12.1 hoặc 12.4 ổn định hơn trên Kaggle T4, bạn có thể thử 12.8 nếu cần\n#!{ACTIVATE} && conda install pytorch torchvision torchaudio pytorch-cuda=12.1 -c pytorch -c nvidia -y\n!{ACTIVATE} && pip install -r requirements.txt\n\n# Cài đặt LLaMA-Factory\n%cd train/LLaMA-Factory\n!{ACTIVATE} && pip install -e .\n\n# Quay lại thư mục gốc dự án\n%cd ../..","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!source /kaggle/working/miniconda/bin/activate unimumer && \\\n MPLBACKEND=Agg llamafactory-cli train train/Uni-MuMER-train.yaml\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T06:03:53.328729Z","iopub.execute_input":"2025-12-27T06:03:53.329382Z"}},"outputs":[{"name":"stdout","text":"[INFO|2025-12-27 06:03:59] llamafactory.launcher:143 >> Initializing 2 distributed tasks at: 127.0.0.1:49795\nW1227 06:04:00.669000 693 site-packages/torch/distributed/run.py:792] \nW1227 06:04:00.669000 693 site-packages/torch/distributed/run.py:792] *****************************************\nW1227 06:04:00.669000 693 site-packages/torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \nW1227 06:04:00.669000 693 site-packages/torch/distributed/run.py:792] *****************************************\n[WARNING|2025-12-27 06:04:07] llamafactory.hparams.parser:148 >> We recommend enable `upcast_layernorm` in quantized training.\n[INFO|2025-12-27 06:04:07] llamafactory.hparams.parser:143 >> Set `ddp_find_unused_parameters` to False in DDP training since LoRA is enabled.\n[INFO|2025-12-27 06:04:07] llamafactory.hparams.parser:465 >> Process rank: 0, world size: 2, device: cuda:0, distributed training: True, compute dtype: torch.bfloat16\n[INFO|2025-12-27 06:04:07] llamafactory.hparams.parser:465 >> Process rank: 1, world size: 2, device: cuda:1, distributed training: True, compute dtype: torch.bfloat16\ntokenizer_config.json: 5.70kB [00:00, 21.9MB/s]\nvocab.json: 2.78MB [00:00, 47.5MB/s]\nmerges.txt: 1.67MB [00:00, 140MB/s]\ntokenizer.json: 7.03MB [00:00, 198MB/s]\n[INFO|tokenization_utils_base.py:2023] 2025-12-27 06:04:07,994 >> loading file vocab.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-VL-3B-Instruct/snapshots/66285546d2b821cf421d4f5eb2576359d3770cd3/vocab.json\n[INFO|tokenization_utils_base.py:2023] 2025-12-27 06:04:07,994 >> loading file merges.txt from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-VL-3B-Instruct/snapshots/66285546d2b821cf421d4f5eb2576359d3770cd3/merges.txt\n[INFO|tokenization_utils_base.py:2023] 2025-12-27 06:04:07,994 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-VL-3B-Instruct/snapshots/66285546d2b821cf421d4f5eb2576359d3770cd3/tokenizer.json\n[INFO|tokenization_utils_base.py:2023] 2025-12-27 06:04:07,994 >> loading file added_tokens.json from cache at None\n[INFO|tokenization_utils_base.py:2023] 2025-12-27 06:04:07,994 >> loading file special_tokens_map.json from cache at None\n[INFO|tokenization_utils_base.py:2023] 2025-12-27 06:04:07,994 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-VL-3B-Instruct/snapshots/66285546d2b821cf421d4f5eb2576359d3770cd3/tokenizer_config.json\n[INFO|tokenization_utils_base.py:2023] 2025-12-27 06:04:07,994 >> loading file chat_template.jinja from cache at None\n[INFO|tokenization_utils_base.py:2299] 2025-12-27 06:04:08,339 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\npreprocessor_config.json: 100%|████████████████| 350/350 [00:00<00:00, 2.61MB/s]\n[INFO|image_processing_base.py:380] 2025-12-27 06:04:08,606 >> loading configuration file preprocessor_config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-VL-3B-Instruct/snapshots/66285546d2b821cf421d4f5eb2576359d3770cd3/preprocessor_config.json\n[INFO|image_processing_base.py:380] 2025-12-27 06:04:08,783 >> loading configuration file preprocessor_config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-VL-3B-Instruct/snapshots/66285546d2b821cf421d4f5eb2576359d3770cd3/preprocessor_config.json\n[INFO|image_processing_base.py:433] 2025-12-27 06:04:08,790 >> Image processor Qwen2VLImageProcessorFast {\n  \"crop_size\": null,\n  \"data_format\": \"channels_first\",\n  \"default_to_square\": true,\n  \"device\": null,\n  \"do_center_crop\": null,\n  \"do_convert_rgb\": true,\n  \"do_normalize\": true,\n  \"do_rescale\": true,\n  \"do_resize\": true,\n  \"image_mean\": [\n    0.48145466,\n    0.4578275,\n    0.40821073\n  ],\n  \"image_processor_type\": \"Qwen2VLImageProcessorFast\",\n  \"image_std\": [\n    0.26862954,\n    0.26130258,\n    0.27577711\n  ],\n  \"input_data_format\": null,\n  \"max_pixels\": 12845056,\n  \"merge_size\": 2,\n  \"min_pixels\": 3136,\n  \"patch_size\": 14,\n  \"processor_class\": \"Qwen2_5_VLProcessor\",\n  \"resample\": 3,\n  \"rescale_factor\": 0.00392156862745098,\n  \"return_tensors\": null,\n  \"size\": {\n    \"longest_edge\": 12845056,\n    \"shortest_edge\": 3136\n  },\n  \"temporal_patch_size\": 2\n}\n\n[INFO|tokenization_utils_base.py:2023] 2025-12-27 06:04:08,949 >> loading file vocab.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-VL-3B-Instruct/snapshots/66285546d2b821cf421d4f5eb2576359d3770cd3/vocab.json\n[INFO|tokenization_utils_base.py:2023] 2025-12-27 06:04:08,949 >> loading file merges.txt from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-VL-3B-Instruct/snapshots/66285546d2b821cf421d4f5eb2576359d3770cd3/merges.txt\n[INFO|tokenization_utils_base.py:2023] 2025-12-27 06:04:08,949 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-VL-3B-Instruct/snapshots/66285546d2b821cf421d4f5eb2576359d3770cd3/tokenizer.json\n[INFO|tokenization_utils_base.py:2023] 2025-12-27 06:04:08,949 >> loading file added_tokens.json from cache at None\n[INFO|tokenization_utils_base.py:2023] 2025-12-27 06:04:08,950 >> loading file special_tokens_map.json from cache at None\n[INFO|tokenization_utils_base.py:2023] 2025-12-27 06:04:08,950 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-VL-3B-Instruct/snapshots/66285546d2b821cf421d4f5eb2576359d3770cd3/tokenizer_config.json\n[INFO|tokenization_utils_base.py:2023] 2025-12-27 06:04:08,950 >> loading file chat_template.jinja from cache at None\n[INFO|tokenization_utils_base.py:2299] 2025-12-27 06:04:09,277 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\nYou have video processor config saved in `preprocessor.json` file which is deprecated. Video processor configs should be saved in their own `video_preprocessor.json` file. You can rename the file or load and save the processor back which renames it automatically. Loading from `preprocessor.json` will be removed in v5.0.\n[WARNING|logging.py:328] 2025-12-27 06:04:09,428 >> You have video processor config saved in `preprocessor.json` file which is deprecated. Video processor configs should be saved in their own `video_preprocessor.json` file. You can rename the file or load and save the processor back which renames it automatically. Loading from `preprocessor.json` will be removed in v5.0.\n[INFO|video_processing_utils.py:629] 2025-12-27 06:04:09,428 >> loading configuration file preprocessor_config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-VL-3B-Instruct/snapshots/66285546d2b821cf421d4f5eb2576359d3770cd3/preprocessor_config.json\nconfig.json: 1.37kB [00:00, 7.67MB/s]\n[INFO|configuration_utils.py:698] 2025-12-27 06:04:09,512 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-VL-3B-Instruct/snapshots/66285546d2b821cf421d4f5eb2576359d3770cd3/config.json\n[INFO|configuration_utils.py:770] 2025-12-27 06:04:09,515 >> Model config Qwen2_5_VLConfig {\n  \"architectures\": [\n    \"Qwen2_5_VLForConditionalGeneration\"\n  ],\n  \"attention_dropout\": 0.0,\n  \"bos_token_id\": 151643,\n  \"eos_token_id\": 151645,\n  \"hidden_act\": \"silu\",\n  \"hidden_size\": 2048,\n  \"image_token_id\": 151655,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 11008,\n  \"max_position_embeddings\": 128000,\n  \"max_window_layers\": 70,\n  \"model_type\": \"qwen2_5_vl\",\n  \"num_attention_heads\": 16,\n  \"num_hidden_layers\": 36,\n  \"num_key_value_heads\": 2,\n  \"rms_norm_eps\": 1e-06,\n  \"rope_scaling\": {\n    \"mrope_section\": [\n      16,\n      24,\n      24\n    ],\n    \"rope_type\": \"default\",\n    \"type\": \"default\"\n  },\n  \"rope_theta\": 1000000.0,\n  \"sliding_window\": 32768,\n  \"text_config\": {\n    \"architectures\": [\n      \"Qwen2_5_VLForConditionalGeneration\"\n    ],\n    \"attention_dropout\": 0.0,\n    \"bos_token_id\": 151643,\n    \"eos_token_id\": 151645,\n    \"hidden_act\": \"silu\",\n    \"hidden_size\": 2048,\n    \"image_token_id\": null,\n    \"initializer_range\": 0.02,\n    \"intermediate_size\": 11008,\n    \"max_position_embeddings\": 128000,\n    \"max_window_layers\": 70,\n    \"model_type\": \"qwen2_5_vl_text\",\n    \"num_attention_heads\": 16,\n    \"num_hidden_layers\": 36,\n    \"num_key_value_heads\": 2,\n    \"rms_norm_eps\": 1e-06,\n    \"rope_scaling\": {\n      \"mrope_section\": [\n        16,\n        24,\n        24\n      ],\n      \"rope_type\": \"default\",\n      \"type\": \"default\"\n    },\n    \"rope_theta\": 1000000.0,\n    \"sliding_window\": 32768,\n    \"tie_word_embeddings\": true,\n    \"torch_dtype\": \"bfloat16\",\n    \"use_cache\": true,\n    \"use_sliding_window\": false,\n    \"video_token_id\": null,\n    \"vision_end_token_id\": 151653,\n    \"vision_start_token_id\": 151652,\n    \"vision_token_id\": 151654,\n    \"vocab_size\": 151936\n  },\n  \"torch_dtype\": \"bfloat16\",\n  \"transformers_version\": \"4.52.4\",\n  \"use_cache\": true,\n  \"use_sliding_window\": false,\n  \"video_token_id\": 151656,\n  \"vision_config\": {\n    \"depth\": 32,\n    \"fullatt_block_indexes\": [\n      7,\n      15,\n      23,\n      31\n    ],\n    \"hidden_act\": \"silu\",\n    \"hidden_size\": 1280,\n    \"in_channels\": 3,\n    \"in_chans\": 3,\n    \"initializer_range\": 0.02,\n    \"intermediate_size\": 3420,\n    \"model_type\": \"qwen2_5_vl\",\n    \"num_heads\": 16,\n    \"out_hidden_size\": 2048,\n    \"patch_size\": 14,\n    \"spatial_merge_size\": 2,\n    \"spatial_patch_size\": 14,\n    \"temporal_patch_size\": 2,\n    \"tokens_per_second\": 2,\n    \"window_size\": 112\n  },\n  \"vision_end_token_id\": 151653,\n  \"vision_start_token_id\": 151652,\n  \"vision_token_id\": 151654,\n  \"vocab_size\": 151936\n}\n\n[INFO|video_processing_utils.py:629] 2025-12-27 06:04:09,662 >> loading configuration file preprocessor_config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2.5-VL-3B-Instruct/snapshots/66285546d2b821cf421d4f5eb2576359d3770cd3/preprocessor_config.json\n[INFO|video_processing_utils.py:683] 2025-12-27 06:04:09,662 >> Video processor Qwen2VLVideoProcessor {\n  \"_valid_kwargs_names\": [\n    \"do_convert_rgb\",\n    \"do_resize\",\n    \"size\",\n    \"size_divisor\",\n    \"default_to_square\",\n    \"resample\",\n    \"do_rescale\",\n    \"rescale_factor\",\n    \"do_normalize\",\n    \"image_mean\",\n    \"image_std\",\n    \"do_pad\",\n    \"do_center_crop\",\n    \"crop_size\",\n    \"data_format\",\n    \"input_data_format\",\n    \"device\",\n    \"min_pixels\",\n    \"max_pixels\",\n    \"patch_size\",\n    \"temporal_patch_size\",\n    \"merge_size\"\n  ],\n  \"crop_size\": null,\n  \"data_format\": \"channels_first\",\n  \"default_to_square\": true,\n  \"device\": null,\n  \"do_center_crop\": null,\n  \"do_convert_rgb\": true,\n  \"do_normalize\": true,\n  \"do_pad\": null,\n  \"do_rescale\": true,\n  \"do_resize\": true,\n  \"image_mean\": [\n    0.48145466,\n    0.4578275,\n    0.40821073\n  ],\n  \"image_processor_type\": \"Qwen2VLImageProcessor\",\n  \"image_std\": [\n    0.26862954,\n    0.26130258,\n    0.27577711\n  ],\n  \"input_data_format\": null,\n  \"max_pixels\": 12845056,\n  \"merge_size\": 2,\n  \"min_pixels\": 3136,\n  \"model_valid_processing_keys\": [\n    \"do_convert_rgb\",\n    \"do_resize\",\n    \"size\",\n    \"size_divisor\",\n    \"default_to_square\",\n    \"resample\",\n    \"do_rescale\",\n    \"rescale_factor\",\n    \"do_normalize\",\n    \"image_mean\",\n    \"image_std\",\n    \"do_pad\",\n    \"do_center_crop\",\n    \"crop_size\",\n    \"data_format\",\n    \"input_data_format\",\n    \"device\",\n    \"min_pixels\",\n    \"max_pixels\",\n    \"patch_size\",\n    \"temporal_patch_size\",\n    \"merge_size\"\n  ],\n  \"patch_size\": 14,\n  \"processor_class\": \"Qwen2_5_VLProcessor\",\n  \"resample\": 3,\n  \"rescale_factor\": 0.00392156862745098,\n  \"size\": {\n    \"longest_edge\": 12845056,\n    \"shortest_edge\": 3136\n  },\n  \"size_divisor\": null,\n  \"temporal_patch_size\": 2,\n  \"video_processor_type\": \"Qwen2VLVideoProcessor\"\n}\n\nchat_template.json: 1.05kB [00:00, 7.35MB/s]\n[rank1]:[W1227 06:04:10.166953160 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.\n[INFO|processing_utils.py:990] 2025-12-27 06:04:10,561 >> Processor Qwen2_5_VLProcessor:\n- image_processor: Qwen2VLImageProcessorFast {\n  \"crop_size\": null,\n  \"data_format\": \"channels_first\",\n  \"default_to_square\": true,\n  \"device\": null,\n  \"do_center_crop\": null,\n  \"do_convert_rgb\": true,\n  \"do_normalize\": true,\n  \"do_rescale\": true,\n  \"do_resize\": true,\n  \"image_mean\": [\n    0.48145466,\n    0.4578275,\n    0.40821073\n  ],\n  \"image_processor_type\": \"Qwen2VLImageProcessorFast\",\n  \"image_std\": [\n    0.26862954,\n    0.26130258,\n    0.27577711\n  ],\n  \"input_data_format\": null,\n  \"max_pixels\": 12845056,\n  \"merge_size\": 2,\n  \"min_pixels\": 3136,\n  \"patch_size\": 14,\n  \"processor_class\": \"Qwen2_5_VLProcessor\",\n  \"resample\": 3,\n  \"rescale_factor\": 0.00392156862745098,\n  \"return_tensors\": null,\n  \"size\": {\n    \"longest_edge\": 12845056,\n    \"shortest_edge\": 3136\n  },\n  \"temporal_patch_size\": 2\n}\n\n- tokenizer: Qwen2TokenizerFast(name_or_path='Qwen/Qwen2.5-VL-3B-Instruct', vocab_size=151643, model_max_length=131072, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n\t151643: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t151644: AddedToken(\"<|im_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t151645: AddedToken(\"<|im_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t151646: AddedToken(\"<|object_ref_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t151647: AddedToken(\"<|object_ref_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t151648: AddedToken(\"<|box_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t151649: AddedToken(\"<|box_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t151650: AddedToken(\"<|quad_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t151651: AddedToken(\"<|quad_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t151652: AddedToken(\"<|vision_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t151653: AddedToken(\"<|vision_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t151654: AddedToken(\"<|vision_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t151655: AddedToken(\"<|image_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t151656: AddedToken(\"<|video_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t151657: AddedToken(\"<tool_call>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n\t151658: AddedToken(\"</tool_call>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n\t151659: AddedToken(\"<|fim_prefix|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n\t151660: AddedToken(\"<|fim_middle|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n\t151661: AddedToken(\"<|fim_suffix|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n\t151662: AddedToken(\"<|fim_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n\t151663: AddedToken(\"<|repo_name|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n\t151664: AddedToken(\"<|file_sep|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False),\n}\n)\n- video_processor: Qwen2VLVideoProcessor {\n  \"_valid_kwargs_names\": [\n    \"do_convert_rgb\",\n    \"do_resize\",\n    \"size\",\n    \"size_divisor\",\n    \"default_to_square\",\n    \"resample\",\n    \"do_rescale\",\n    \"rescale_factor\",\n    \"do_normalize\",\n    \"image_mean\",\n    \"image_std\",\n    \"do_pad\",\n    \"do_center_crop\",\n    \"crop_size\",\n    \"data_format\",\n    \"input_data_format\",\n    \"device\",\n    \"min_pixels\",\n    \"max_pixels\",\n    \"patch_size\",\n    \"temporal_patch_size\",\n    \"merge_size\"\n  ],\n  \"crop_size\": null,\n  \"data_format\": \"channels_first\",\n  \"default_to_square\": true,\n  \"device\": null,\n  \"do_center_crop\": null,\n  \"do_convert_rgb\": true,\n  \"do_normalize\": true,\n  \"do_pad\": null,\n  \"do_rescale\": true,\n  \"do_resize\": true,\n  \"image_mean\": [\n    0.48145466,\n    0.4578275,\n    0.40821073\n  ],\n  \"image_processor_type\": \"Qwen2VLImageProcessor\",\n  \"image_std\": [\n    0.26862954,\n    0.26130258,\n    0.27577711\n  ],\n  \"input_data_format\": null,\n  \"max_pixels\": 12845056,\n  \"merge_size\": 2,\n  \"min_pixels\": 3136,\n  \"model_valid_processing_keys\": [\n    \"do_convert_rgb\",\n    \"do_resize\",\n    \"size\",\n    \"size_divisor\",\n    \"default_to_square\",\n    \"resample\",\n    \"do_rescale\",\n    \"rescale_factor\",\n    \"do_normalize\",\n    \"image_mean\",\n    \"image_std\",\n    \"do_pad\",\n    \"do_center_crop\",\n    \"crop_size\",\n    \"data_format\",\n    \"input_data_format\",\n    \"device\",\n    \"min_pixels\",\n    \"max_pixels\",\n    \"patch_size\",\n    \"temporal_patch_size\",\n    \"merge_size\"\n  ],\n  \"patch_size\": 14,\n  \"processor_class\": \"Qwen2_5_VLProcessor\",\n  \"resample\": 3,\n  \"rescale_factor\": 0.00392156862745098,\n  \"size\": {\n    \"longest_edge\": 12845056,\n    \"shortest_edge\": 3136\n  },\n  \"size_divisor\": null,\n  \"temporal_patch_size\": 2,\n  \"video_processor_type\": \"Qwen2VLVideoProcessor\"\n}\n\n\n{\n  \"processor_class\": \"Qwen2_5_VLProcessor\"\n}\n\n[INFO|2025-12-27 06:04:10] llamafactory.data.loader:143 >> Loading dataset phxember/Uni-MuMER-Data...\nREADME.md: 15.9kB [00:00, 58.1MB/s]\ncrohme2023/crohme2023-00000-of-00001.par(…): 100%|█| 240M/240M [00:04<00:00, 57.\nSetting num_proc from 16 back to 1 for the train split to disable multiprocessing as it only contains one shard.\nGenerating train split: 100%|███| 11616/11616 [00:00<00:00, 25245.18 examples/s]\nConverting format of dataset (num_proc=16): 100%|█| 5000/5000 [00:04<00:00, 1026\n[INFO|2025-12-27 06:04:23] llamafactory.data.loader:143 >> Loading dataset phxember/Uni-MuMER-Data...\ncrohme2023_can/crohme2023_can-00000-of-0(…): 100%|█| 240M/240M [00:03<00:00, 70.\nSetting num_proc from 16 back to 1 for the train split to disable multiprocessing as it only contains one shard.\nGenerating train split: 100%|███| 11616/11616 [00:00<00:00, 34805.56 examples/s]\nConverting format of dataset (num_proc=16): 100%|█| 5000/5000 [00:04<00:00, 1041\n[INFO|2025-12-27 06:04:33] llamafactory.data.loader:143 >> Loading dataset phxember/Uni-MuMER-Data...\ncrohme2023_error_find/crohme2023_error_f(…): 100%|█| 81.2M/81.2M [00:04<00:00, 1\nSetting num_proc from 16 back to 1 for the train split to disable multiprocessing as it only contains one shard.\nGenerating train split: 100%|█████| 6287/6287 [00:00<00:00, 41459.79 examples/s]\nConverting format of dataset (num_proc=16): 100%|█| 5000/5000 [00:07<00:00, 698.\n[INFO|2025-12-27 06:04:47] llamafactory.data.loader:143 >> Loading dataset phxember/Uni-MuMER-Data...\ncrohme2023_error_fix/crohme2023_error_fi(…): 100%|█| 80.0M/80.0M [00:02<00:00, 3\nSetting num_proc from 16 back to 1 for the train split to disable multiprocessing as it only contains one shard.\nGenerating train split: 100%|█████| 8860/8860 [00:00<00:00, 43589.09 examples/s]\nConverting format of dataset (num_proc=16): 100%|█| 5000/5000 [00:05<00:00, 937.\n[INFO|2025-12-27 06:04:56] llamafactory.data.loader:143 >> Loading dataset phxember/Uni-MuMER-Data...\ncrohme2023_tree/crohme2023_tree-00000-of(…): 100%|█| 240M/240M [00:02<00:00, 88.\nSetting num_proc from 16 back to 1 for the train split to disable multiprocessing as it only contains one shard.\nGenerating train split: 100%|███| 11616/11616 [00:00<00:00, 36575.46 examples/s]\nConverting format of dataset (num_proc=16): 100%|█| 5000/5000 [00:04<00:00, 1024\n[INFO|2025-12-27 06:05:06] llamafactory.data.loader:143 >> Loading dataset phxember/Uni-MuMER-Data...\ncrohme_train/crohme_train-00000-of-00001(…):   0%|  | 0.00/71.3M [00:00<?, ?B/s]","output_type":"stream"}],"execution_count":null}]}