# Uni-MuMER: Fine-tuning Th·ªëng nh·∫•t ƒêa nhi·ªám c·ªßa M√¥ h√¨nh Vision-Language cho Nh·∫≠n d·∫°ng Bi·ªÉu th·ª©c To√°n h·ªçc Vi·∫øt tay

<p align="center">
    <a href="https://arxiv.org/abs/2505.23566"><img src="https://img.shields.io/badge/üìÑ-Paper-red"></a>
    <a href="https://huggingface.co/collections/phxember/uni-mumer-68bfba4747e9289232f3d89e"><img src="https://img.shields.io/badge/ü§ó HuggingFace-Data & Models-green"></a>
</p>

## M√¥ t·∫£

Ch√∫ng t√¥i gi·ªõi thi·ªáu Uni-MuMER, m·ªôt ph∆∞∆°ng ph√°p fine-tune ho√†n to√†n m√¥ h√¨nh Qwen2.5-VL-3B cho t√°c v·ª• HMER m√† kh√¥ng thay ƒë·ªïi ki·∫øn tr√∫c c·ªßa n√≥, hi·ªáu qu·∫£ trong vi·ªác t√≠ch h·ª£p ki·∫øn th·ª©c chuy√™n ng√†nh v√†o m·ªôt framework t·ªïng qu√°t. Ph∆∞∆°ng ph√°p c·ªßa ch√∫ng t√¥i t√≠ch h·ª£p ba t√°c v·ª• d·ª±a tr√™n d·ªØ li·ªáu: Tree-Aware Chain-of-Thought (Tree-CoT) cho l·∫≠p lu·∫≠n kh√¥ng gian c√≥ c·∫•u tr√∫c, Error-Driven Learning (EDL) ƒë·ªÉ gi·∫£m nh·∫ßm l·∫´n gi·ªØa c√°c k√Ω t·ª± tr·ª±c quan t∆∞∆°ng t·ª±, v√† Symbol Counting (SC) ƒë·ªÉ c·∫£i thi·ªán t√≠nh nh·∫•t qu√°n trong nh·∫≠n d·∫°ng c√°c bi·ªÉu th·ª©c d√†i.

![Uni-MuMER](./asserts/fig/main_fig.drawio_00.png)

C√°c th√≠ nghi·ªám tr√™n dataset CROHME v√† HME100K cho th·∫•y Uni-MuMER ƒë·∫°t ƒë∆∞·ª£c hi·ªáu su·∫•t state-of-the-art m·ªõi, v∆∞·ª£t qua m√¥ h√¨nh chuy√™n bi·ªát nh·∫π t·ªët nh·∫•t SSAN 16.31% v√† VLM h√†ng ƒë·∫ßu Gemini2.5-flash 24.42% trong thi·∫øt l·∫≠p zero-shot.

![intro](./asserts/fig/CROHME_00.png)

## üì¢ C·∫≠p nh·∫≠t

- **2025-09-18**: C√¥ng tr√¨nh n√†y ƒë∆∞·ª£c ch·∫•p nh·∫≠n t·∫°i NeurIPS 2025 v·ªõi danh hi·ªáu Spotlight (688/21575).
- **2025-09-09**: Ph√°t h√†nh dataset ([Uni-MuMER-Data](https://huggingface.co/datasets/phxember/Uni-MuMER-Data) v√† [valid/test data](https://drive.google.com/drive/folders/1T8a3WxICZVl1NJ99hu9tuuqqNZoxGhXq?usp=sharing)) v√† m√£ ngu·ªìn training. [Xem ph·∫ßn Training]
- **2025-06-02**: Ph√°t h√†nh tr·ªçng s·ªë m√¥ h√¨nh v√† script inference.

## üîß H∆∞·ªõng d·∫´n C√†i ƒë·∫∑t v√† Ch·∫°y Chi ti·∫øt

### Y√™u c·∫ßu h·ªá th·ªëng
- Ubuntu (ho·∫∑c Linux t∆∞∆°ng th√≠ch)
- GPU v·ªõi CUDA (khuy·∫øn ngh·ªã)
- Conda ho·∫∑c Miniconda
- Python 3.8+

### B∆∞·ªõc 1: Di chuy·ªÉn v√†o th∆∞ m·ª•c project

```bash
cd /home/khai/Desktop/github/Uni-MuMER
```

### B∆∞·ªõc 2: T·∫°o m√¥i tr∆∞·ªùng conda

```bash
# T·∫°o m√¥i tr∆∞·ªùng conda m·ªõi v·ªõi Python 3.10
conda create -n unimumer python=3.10 -y

# K√≠ch ho·∫°t m√¥i tr∆∞·ªùng
conda activate unimumer
```

**L∆∞u √Ω:** M·ªói l·∫ßn m·ªü terminal m·ªõi, b·∫°n c·∫ßn k√≠ch ho·∫°t l·∫°i m√¥i tr∆∞·ªùng:
```bash
conda activate unimumer
```

### B∆∞·ªõc 3: Ki·ªÉm tra phi√™n b·∫£n CUDA (n·∫øu c√≥ GPU)

```bash
# Ki·ªÉm tra phi√™n b·∫£n CUDA
nvidia-smi
```

Ghi nh·ªõ phi√™n b·∫£n CUDA (v√≠ d·ª•: 12.4, 11.8, v.v.) ƒë·ªÉ c√†i ƒë·∫∑t PyTorch ph√π h·ª£p.

### B∆∞·ªõc 4: C√†i ƒë·∫∑t PyTorch v·ªõi CUDA (b·ªè)

```bash
# ƒê·∫£m b·∫£o ƒëang ·ªü trong m√¥i tr∆∞·ªùng conda
conda activate unimumer

# C√†i PyTorch v·ªõi CUDA 12.4 (thay ƒë·ªïi theo phi√™n b·∫£n CUDA c·ªßa b·∫°n)
conda install pytorch torchvision torchaudio pytorch-cuda=12.4 -c pytorch -c nvidia -y
```

**N·∫øu CUDA phi√™n b·∫£n kh√°c:**
- CUDA 11.8: `conda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia -y`
- CUDA 12.1: `conda install pytorch torchvision torchaudio pytorch-cuda=12.1 -c pytorch -c nvidia -y`

**N·∫øu kh√¥ng c√≥ GPU:**
```bash
conda install pytorch torchvision torchaudio cpuonly -c pytorch -y
```

### B∆∞·ªõc 5: C√†i ƒë·∫∑t Python dependencies

```bash
# ƒê·∫£m b·∫£o ƒëang ·ªü trong m√¥i tr∆∞·ªùng conda
conda activate unimumer

# Di chuy·ªÉn v√†o th∆∞ m·ª•c project (n·∫øu ch∆∞a ·ªü ƒë√≥)
cd /home/khai/Desktop/github/Uni-MuMER

# C√†i ƒë·∫∑t c√°c package c·∫ßn thi·∫øt
pip install -r requirements.txt
```

Qu√° tr√¨nh c√†i ƒë·∫∑t c√≥ th·ªÉ m·∫•t v√†i ph√∫t. ƒê·ª£i ƒë·∫øn khi ho√†n t·∫•t.

### B∆∞·ªõc 6: Gi·∫£i n√©n dataset

```bash
# ƒê·∫£m b·∫£o ƒëang ·ªü trong th∆∞ m·ª•c project
cd /home/khai/Desktop/github/Uni-MuMER

# Gi·∫£i n√©n file data.zip
unzip data.zip
```

Sau khi gi·∫£i n√©n, ki·ªÉm tra c·∫•u tr√∫c th∆∞ m·ª•c:
```bash
ls -la data/
```

B·∫°n s·∫Ω th·∫•y c√°c th∆∞ m·ª•c:
```
data/
‚îú‚îÄ‚îÄ CROHME/
‚îú‚îÄ‚îÄ CROHME2023/
‚îú‚îÄ‚îÄ HME100K/
‚îú‚îÄ‚îÄ Im2LaTeXv2/
‚îú‚îÄ‚îÄ MathWriting/
‚îî‚îÄ‚îÄ MNE/
```

### B∆∞·ªõc 7: Ki·ªÉm tra model ƒë√£ clone

```bash
# Ki·ªÉm tra th∆∞ m·ª•c model
ls -la Uni-MuMER-Qwen2.5-VL-3B/
```

B·∫°n s·∫Ω th·∫•y c√°c file nh∆∞ `config.json`, `generation_config.json`, v.v.

## üèÉ Inference (D·ª± ƒëo√°n)

**Quan tr·ªçng:** Lu√¥n k√≠ch ho·∫°t m√¥i tr∆∞·ªùng conda tr∆∞·ªõc khi ch·∫°y:
```bash
conda activate unimumer
cd /home/khai/Desktop/github/Uni-MuMER
```

### C√°ch 1: Ch·∫°y t·∫•t c·∫£ c√°c dataset (Khuy·∫øn ngh·ªã)

```bash
# K√≠ch ho·∫°t m√¥i tr∆∞·ªùng
conda activate unimumer

# Di chuy·ªÉn v√†o th∆∞ m·ª•c project
cd /home/khai/Desktop/github/Uni-MuMER

# Ch·∫°y inference cho t·∫•t c·∫£ dataset
bash eval/eval_all.sh -m ./Uni-MuMER-Qwen2.5-VL-3B -b 32768
```

**V·ªõi GPU c·ª• th·ªÉ:**
```bash
# Ch·ªâ ƒë·ªãnh GPU 0
export CUDA_VISIBLE_DEVICES=0
conda activate unimumer
cd /home/khai/Desktop/github/Uni-MuMER
bash eval/eval_all.sh -m ./Uni-MuMER-Qwen2.5-VL-3B -b 32768

# Ho·∫∑c s·ª≠ d·ª•ng nhi·ªÅu GPU (v√≠ d·ª•: GPU 0 v√† 1)
export CUDA_VISIBLE_DEVICES=0,1
conda activate unimumer
cd /home/khai/Desktop/github/Uni-MuMER
bash eval/eval_all.sh -m ./Uni-MuMER-Qwen2.5-VL-3B -b 32768
```

**N·∫øu g·∫∑p l·ªói OOM (Out of Memory), gi·∫£m batch size:**
```bash
conda activate unimumer
cd /home/khai/Desktop/github/Uni-MuMER
bash eval/eval_all.sh -m ./Uni-MuMER-Qwen2.5-VL-3B -b 16384
```

### C√°ch 2: Ch·∫°y t·ª´ng dataset ri√™ng l·∫ª

#### Dataset CROHME:
```bash
conda activate unimumer
cd /home/khai/Desktop/github/Uni-MuMER
bash eval/eval_crohme.sh -i data/CROHME/prompts -o data/CROHME/results -m ./Uni-MuMER-Qwen2.5-VL-3B -b 32768
```

#### Dataset CROHME2023:
```bash
conda activate unimumer
cd /home/khai/Desktop/github/Uni-MuMER
bash eval/eval_crohme2023.sh -i data/CROHME2023/prompts -o data/CROHME2023/results -m ./Uni-MuMER-Qwen2.5-VL-3B -b 32768
```

#### Dataset HME100K:
```bash
conda activate unimumer
cd /home/khai/Desktop/github/Uni-MuMER
bash eval/eval_hme100k.sh -i data/HME100K/prompts -o data/HME100K/results -m ./Uni-MuMER-Qwen2.5-VL-3B -b 32768
```

#### Dataset Im2LaTeXv2:
```bash
conda activate unimumer
cd /home/khai/Desktop/github/Uni-MuMER
bash eval/eval_im2latexv2.sh -i data/Im2LaTeXv2/prompts -o data/Im2LaTeXv2/results -m ./Uni-MuMER-Qwen2.5-VL-3B -b 32768
```

#### Dataset MathWriting:
```bash
conda activate unimumer
cd /home/khai/Desktop/github/Uni-MuMER
bash eval/eval_mathwriting.sh -i data/MathWriting/prompts -o data/MathWriting/results -m ./Uni-MuMER-Qwen2.5-VL-3B -b 32768
```

#### Dataset MNE:
```bash
conda activate unimumer
cd /home/khai/Desktop/github/Uni-MuMER
bash eval/eval_MNE.sh -i data/MNE/prompts -o data/MNE/results -m ./Uni-MuMER-Qwen2.5-VL-3B -b 32768
```

### C√°ch 3: Ch·∫°y tr·ª±c ti·∫øp b·∫±ng Python

```bash
conda activate unimumer
cd /home/khai/Desktop/github/Uni-MuMER

# V√≠ d·ª•: Ch·∫°y inference cho CROHME
python scripts/vllm_infer.py \
    --input-dir data/CROHME/prompts \
    --output-dir data/CROHME/results \
    --model ./Uni-MuMER-Qwen2.5-VL-3B \
    --batch-size 32768
```

**V√≠ d·ª• kh√°c - HME100K:**
```bash
conda activate unimumer
cd /home/khai/Desktop/github/Uni-MuMER

python scripts/vllm_infer.py \
    --input-dir data/HME100K/prompts \
    --output-dir data/HME100K/results \
    --model ./Uni-MuMER-Qwen2.5-VL-3B \
    --batch-size 32768
```

## üìä Xem k·∫øt qu·∫£

Sau khi ch·∫°y inference, k·∫øt qu·∫£ s·∫Ω ƒë∆∞·ª£c l∆∞u trong c√°c th∆∞ m·ª•c t∆∞∆°ng ·ª©ng:

```bash
# Xem k·∫øt qu·∫£ CROHME
cat data/CROHME/results/crohme_2014_results.txt
cat data/CROHME/results/crohme_2016_results.txt
cat data/CROHME/results/crohme_2019_results.txt

# Xem k·∫øt qu·∫£ HME100K
cat data/HME100K/results/hme100k_test_results.txt

# Xem k·∫øt qu·∫£ CROHME2023
cat data/CROHME2023/results/crohme2023_test_results.txt
```

C√°c file k·∫øt qu·∫£ bao g·ªìm:
- `*_pred.json`: D·ª± ƒëo√°n c·ªßa model
- `*_results.txt`: K·∫øt qu·∫£ ƒë√°nh gi√° (accuracy, edit distance, etc.)

## üèãÔ∏è Training (N·∫øu c·∫ßn)

M√£ ngu·ªìn training ph·ª• thu·ªôc v√†o [LLaMA-Factory](https://github.com/hiyouga/LLaMA-Factory).

### C√†i ƒë·∫∑t dependencies cho training:

```bash
conda activate unimumer
cd /home/khai/Desktop/github/Uni-MuMER

# C√†i ƒë·∫∑t c√°c package c·∫ßn thi·∫øt cho training
pip install -r requirements_training.txt
```

Qu√° tr√¨nh c√†i ƒë·∫∑t c√≥ th·ªÉ m·∫•t kh√° l√¢u (10-30 ph√∫t t√πy v√†o t·ªëc ƒë·ªô m·∫°ng).

### Ch·∫°y training:

```bash
conda activate unimumer
cd /home/khai/Desktop/github/Uni-MuMER

# Ch·∫°y training
llamafactory-cli train train/Uni-MuMER-train.yaml
```

## ‚ö†Ô∏è Troubleshooting

### L·ªói "conda: command not found"

C√†i ƒë·∫∑t conda/miniconda:
```bash
# T·∫£i Miniconda
wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh

# C√†i ƒë·∫∑t
bash Miniconda3-latest-Linux-x86_64.sh

# Kh·ªüi ƒë·ªông l·∫°i terminal ho·∫∑c ch·∫°y:
source ~/.bashrc

# Sau ƒë√≥ t·∫°o l·∫°i m√¥i tr∆∞·ªùng
conda create -n unimumer python=3.10 -y
```

### L·ªói CUDA kh√¥ng kh·ªõp

Ki·ªÉm tra v√† c√†i l·∫°i PyTorch v·ªõi ƒë√∫ng phi√™n b·∫£n CUDA:
```bash
conda activate unimumer

# Ki·ªÉm tra phi√™n b·∫£n CUDA
nvidia-smi

# G·ª° PyTorch c≈© (n·∫øu c·∫ßn)
conda uninstall pytorch torchvision torchaudio -y

# C√†i l·∫°i v·ªõi phi√™n b·∫£n CUDA ƒë√∫ng (v√≠ d·ª•: 12.4)
conda install pytorch torchvision torchaudio pytorch-cuda=12.4 -c pytorch -c nvidia -y
```

### L·ªói thi·∫øu module

C√†i l·∫°i dependencies:
```bash
conda activate unimumer
cd /home/khai/Desktop/github/Uni-MuMER
pip install -r requirements.txt
```

### L·ªói OOM (Out of Memory)

Gi·∫£m batch size:
```bash
# Th·ª≠ v·ªõi batch size nh·ªè h∆°n
conda activate unimumer
cd /home/khai/Desktop/github/Uni-MuMER
bash eval/eval_all.sh -m ./Uni-MuMER-Qwen2.5-VL-3B -b 16384

# Ho·∫∑c nh·ªè h∆°n n·ªØa
bash eval/eval_all.sh -m ./Uni-MuMER-Qwen2.5-VL-3B -b 8192
```

### Qu√™n k√≠ch ho·∫°t m√¥i tr∆∞·ªùng

Lu√¥n nh·ªõ k√≠ch ho·∫°t m√¥i tr∆∞·ªùng tr∆∞·ªõc khi ch·∫°y:
```bash
conda activate unimumer
cd /home/khai/Desktop/github/Uni-MuMER
bash eval/eval_all.sh -m ./Uni-MuMER-Qwen2.5-VL-3B -b 32768
```

### L·ªói "No such file or directory"

ƒê·∫£m b·∫£o ƒëang ·ªü ƒë√∫ng th∆∞ m·ª•c project:
```bash
# Ki·ªÉm tra th∆∞ m·ª•c hi·ªán t·∫°i
pwd

# N·∫øu kh√¥ng ƒë√∫ng, di chuy·ªÉn ƒë·∫øn th∆∞ m·ª•c project
cd /home/khai/Desktop/github/Uni-MuMER

# Ki·ªÉm tra l·∫°i
ls -la
```

### L·ªói khi import vllm

C√†i l·∫°i vllm:
```bash
conda activate unimumer
pip uninstall vllm -y
pip install vllm==0.8.5
```

## ‚úÖ TODO

- [x] Inference code and pretrained models.
- [x] Evaluation code.
- [x] Training code.
- [x] Training data.
- [ ] Preprocess code.

## üôè L·ªùi c·∫£m ∆°n

C·∫£m ∆°n c√°c d·ª± √°n sau:

- [CoMER](https://github.com/Green-Wood/CoMER)
- [PosFormer](https://github.com/SJTU-DeepVisionLab/PosFormer)
- [TAMER](https://github.com/qingzhenduyu/TAMER)
- [LLaMA-Factory](https://github.com/hiyouga/LLaMA-Factory)
- [MathNet](https://github.com/felix-schmitt/MathNet)

## üìù Tr√≠ch d·∫´n

N·∫øu b·∫°n th·∫•y Uni-MuMER h·ªØu √≠ch cho nghi√™n c·ª©u c·ªßa m√¨nh, vui l√≤ng tr√≠ch d·∫´n b√†i b√°o c·ªßa ch√∫ng t√¥i:

```bibtex
@article{li2025unimumer,
  title = {Uni-MuMER: Unified Multi-Task Fine-Tuning of Vision-Language Model for Handwritten Mathematical Expression Recognition},
  author = {Li, Yu and Jiang, Jin and Zhu, Jianhua and Peng, Shuai and Wei, Baole and Zhou, Yuxuan and Gao, Liangcai},
  year = {2025},
  journal={arXiv preprint arXiv:2505.23566},
}
```
